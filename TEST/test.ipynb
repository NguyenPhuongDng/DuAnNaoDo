{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c62e6813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒêang ch·∫°y YOLOv11 realtime ‚Äî nh·∫•n 'q' ƒë·ªÉ tho√°t.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "def main():\n",
    "    # Load model YOLOv11n\n",
    "    model = YOLO(\"yolo11n.pt\")  # ho·∫∑c \"yolo11s.pt\" n·∫øu mu·ªën model ch√≠nh x√°c h∆°n\n",
    "\n",
    "    # M·ªü camera (0 = webcam m·∫∑c ƒë·ªãnh)\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Kh√¥ng th·ªÉ m·ªü webcam!\")\n",
    "        return\n",
    "\n",
    "    prev_time = 0\n",
    "\n",
    "    print(\"ƒêang ch·∫°y YOLOv11 realtime ‚Äî nh·∫•n 'q' ƒë·ªÉ tho√°t.\")\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Ch·∫°y d·ª± ƒëo√°n (inference)\n",
    "        results = model(frame, verbose=False)\n",
    "\n",
    "        # V·∫Ω bounding box tr·ª±c ti·∫øp\n",
    "        annotated_frame = results[0].plot()\n",
    "\n",
    "        # T√≠nh FPS\n",
    "        curr_time = time.time()\n",
    "        fps = 1 / (curr_time - prev_time) if prev_time else 0\n",
    "        prev_time = curr_time\n",
    "        cv2.putText(annotated_frame, f\"FPS: {fps:.1f}\", (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        # Hi·ªÉn th·ªã ·∫£nh c√≥ box\n",
    "        cv2.imshow(\"YOLOv11 Camera\", annotated_frame)\n",
    "\n",
    "        # Tho√°t b·∫±ng ph√≠m q\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f151a11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "# Danh s√°ch c√°c ph∆∞∆°ng ti·ªán giao th√¥ng\n",
    "vehicles = [\n",
    "    \"car\", \"motorcycle\", \"bicycle\", \"bus\", \"truck\",\n",
    "    \"train\", \"airplane\", \"boat\", \"ship\", \"scooter\",\n",
    "    \"van\", \"helicopter\"\n",
    "]\n",
    "\n",
    "\n",
    "def detect_image(model, image_path, save_result=False):\n",
    "    \"\"\"Nh·∫≠n d·∫°ng v√† ch·ªâ hi·ªÉn th·ªã c√°c ph∆∞∆°ng ti·ªán giao th√¥ng\"\"\"\n",
    "    image = cv2.imread(str(image_path))\n",
    "    if image is None:\n",
    "        print(f\"L·ªói: Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh {image_path}\")\n",
    "        return\n",
    "\n",
    "    # Ch·∫°y nh·∫≠n d·∫°ng\n",
    "    results = model(image, verbose=False)\n",
    "    r = results[0]\n",
    "\n",
    "    # L·∫•y th√¥ng tin box\n",
    "    names = model.names  # t√™n c√°c l·ªõp\n",
    "    boxes = r.boxes\n",
    "\n",
    "    # L·ªçc ƒë·ªëi t∆∞·ª£ng ch·ªâ l√† ph∆∞∆°ng ti·ªán\n",
    "    for box in boxes:\n",
    "        cls_id = int(box.cls[0])\n",
    "        conf = float(box.conf[0])\n",
    "        label = names[cls_id]\n",
    "\n",
    "        if label.lower() not in vehicles:\n",
    "            continue  # b·ªè qua n·∫øu kh√¥ng ph·∫£i ph∆∞∆°ng ti·ªán\n",
    "\n",
    "        # L·∫•y t·ªça ƒë·ªô bbox\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(\n",
    "            image,\n",
    "            f\"{label} {conf:.2f}\",\n",
    "            (x1, y1 - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.6,\n",
    "            (0, 255, 0),\n",
    "            2\n",
    "        )\n",
    "\n",
    "    # Hi·ªÉn th·ªã ·∫£nh k·∫øt qu·∫£\n",
    "    cv2.imshow(\"Vehicle Detection (YOLOv11)\", image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    if save_result:\n",
    "        out_path = Path(image_path).stem + \"_vehicles.jpg\"\n",
    "        cv2.imwrite(out_path, image)\n",
    "        print(f\"ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£: {out_path}\")\n",
    "\n",
    "\n",
    "# --- Ch·∫°y th·ª≠ ---\n",
    "detect_image(YOLO(\"yolo11x.pt\"), \"image/download (2).jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c00a121a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S·ª≠ d·ª•ng thi·∫øt b·ªã: cuda\n",
      "ƒêang ch·∫°y video... nh·∫•n 'q' ƒë·ªÉ tho√°t.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "\n",
    "# Danh s√°ch ph∆∞∆°ng ti·ªán giao th√¥ng\n",
    "vehicles = [\n",
    "    \"car\", \"motorcycle\", \"bicycle\", \"bus\", \"truck\",\n",
    "    \"train\", \"airplane\", \"boat\", \"ship\", \"scooter\",\n",
    "    \"van\", \"helicopter\"\n",
    "]\n",
    "\n",
    "def detect_video(model, video_path=0, conf_thres=0.3):\n",
    "    \"\"\"Nh·∫≠n d·∫°ng ph∆∞∆°ng ti·ªán giao th√¥ng trong video, t√≠nh v·∫≠n t·ªëc (px/s)\"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "    print(f\"S·ª≠ d·ª•ng thi·∫øt b·ªã: {device}\")\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Kh√¥ng th·ªÉ m·ªü video: {video_path}\")\n",
    "        return\n",
    "    \n",
    "    prev_time = time.time()\n",
    "    prev_positions = {}  # L∆∞u t√¢m bbox c≈© c·ªßa m·ªói xe (index: class_id + v·ªã tr√≠)\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 30\n",
    "    print(\"ƒêang ch·∫°y video... nh·∫•n 'q' ƒë·ªÉ tho√°t.\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        results = model(frame, conf=conf_thres, verbose=False)\n",
    "        r = results[0]\n",
    "        names = model.names\n",
    "        boxes = r.boxes\n",
    "\n",
    "        current_positions = {}\n",
    "\n",
    "        for i, box in enumerate(boxes):\n",
    "            cls_id = int(box.cls[0])\n",
    "            label = names[cls_id].lower()\n",
    "            conf = float(box.conf[0])\n",
    "\n",
    "            if label not in vehicles or conf < conf_thres:\n",
    "                continue\n",
    "\n",
    "            # T·ªça ƒë·ªô bounding box\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            cx, cy = (x1 + x2) // 2, (y1 + y2) // 2  # t√¢m bbox\n",
    "\n",
    "            # T√≠nh v·∫≠n t·ªëc (n·∫øu c√≥ d·ªØ li·ªáu tr∆∞·ªõc)\n",
    "            velocity = 0.0\n",
    "            key = f\"{cls_id}_{i}\"  # t·∫°m d√πng index + class l√†m ID\n",
    "            if key in prev_positions:\n",
    "                px_prev, py_prev = prev_positions[key]\n",
    "                dist = math.sqrt((cx - px_prev) ** 2 + (cy - py_prev) ** 2)\n",
    "                velocity = dist * fps * 3.6  # pixel m·ªói gi√¢y\n",
    "            current_positions[key] = (cx, cy)\n",
    "\n",
    "            # V·∫Ω bounding box\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                f\"{label} v={velocity:.1f}km/h\",\n",
    "                (x1, y1 - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,\n",
    "                (0, 0, 0),\n",
    "                2\n",
    "            )\n",
    "\n",
    "        prev_positions = current_positions\n",
    "\n",
    "        # Hi·ªÉn th·ªã FPS\n",
    "        curr_time = time.time()\n",
    "        fps_disp = 1 / (curr_time - prev_time) if prev_time else 0\n",
    "        prev_time = curr_time\n",
    "        cv2.putText(frame, f\"FPS: {fps_disp:.1f}\", (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow(\"Vehicle Detection with Speed (YOLOv11)\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# --- Ch·∫°y th·ª≠ ---\n",
    "if __name__ == \"__main__\":\n",
    "    model = YOLO(\"yolo11x.pt\")\n",
    "    detect_video(model, \"vidieo/2165-155327596.mp4\")  # ho·∫∑c detect_video(model, 0) ƒë·ªÉ d√πng webcam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09500ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì S·ª≠ d·ª•ng GPU: NVIDIA GeForce GTX 1650\n",
      "‚úì Video: 1280x720 @ 25.0 FPS\n",
      "üé¨ ƒêang ch·∫°y... nh·∫•n 'q' ƒë·ªÉ tho√°t\n",
      "‚úì Ho√†n th√†nh!\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque, defaultdict\n",
    "\n",
    "# ===============================\n",
    "# üéõÔ∏è C·∫§U H√åNH D·ªÑ CH·ªàNH S·ª¨A\n",
    "# ===============================\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n ƒë·∫øn m√¥ h√¨nh YOLO\n",
    "MODEL_PATH = \"yolo11s.pt\"\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n video ƒë·∫ßu v√†o (ho·∫∑c 0 cho webcam)\n",
    "VIDEO_PATH = \"vidieo/1900-151662242_small.mp4\"\n",
    "\n",
    "# Ng∆∞·ª°ng tin c·∫≠y cho ph√°t hi·ªán\n",
    "CONF_THRESHOLD = 0.4\n",
    "\n",
    "# K√≠ch th∆∞·ªõc m·ª•c ti√™u khi resize video (ƒë·ªÉ tƒÉng FPS)\n",
    "TARGET_WIDTH = 1280\n",
    "\n",
    "# C·∫•u h√¨nh Tracker\n",
    "TRACKER_MAX_DISAPPEARED = 30   # S·ªë frame cho ph√©p m·∫•t tr∆∞·ªõc khi x√≥a\n",
    "TRACKER_MAX_DISTANCE = 100     # Kho·∫£ng c√°ch t·ªëi ƒëa ƒë·ªÉ match object\n",
    "\n",
    "# H·ªá s·ªë chuy·ªÉn ƒë·ªïi pixel ‚Üí km/h (tu·ª≥ theo video th·ª±c t·∫ø)\n",
    "PIXEL_TO_KMH = 0.5\n",
    "\n",
    "# FPS trung b√¨nh ƒë·ªÉ l√†m m∆∞·ª£t hi·ªÉn th·ªã\n",
    "FPS_SMOOTHING_WINDOW = 30\n",
    "\n",
    "# Danh s√°ch ph∆∞∆°ng ti·ªán giao th√¥ng c·∫ßn theo d√µi\n",
    "VEHICLES = [\n",
    "    \"car\", \"motorcycle\", \"bicycle\", \"bus\", \"truck\",\n",
    "    \"train\", \"airplane\", \"boat\", \"ship\", \"scooter\",\n",
    "    \"van\", \"helicopter\"\n",
    "]\n",
    "\n",
    "# ===============================\n",
    "# üöó CH∆Ø∆†NG TR√åNH CH√çNH\n",
    "# ===============================\n",
    "\n",
    "class VehicleTracker:\n",
    "    \"\"\"Tracker ƒë·ªÉ theo d√µi ph∆∞∆°ng ti·ªán v·ªõi ID ·ªïn ƒë·ªãnh\"\"\"\n",
    "    def __init__(self, max_disappeared=30, max_distance=100):\n",
    "        self.next_id = 0\n",
    "        self.objects = {}  # {id: (centroid, class_id, bbox)}\n",
    "        self.disappeared = {}  # {id: s·ªë frame m·∫•t}\n",
    "        self.velocities = defaultdict(lambda: deque(maxlen=10))  # L∆∞u l·ªãch s·ª≠ v·∫≠n t·ªëc\n",
    "        self.max_disappeared = max_disappeared\n",
    "        self.max_distance = max_distance\n",
    "        \n",
    "    def register(self, centroid, class_id, bbox):\n",
    "        \"\"\"ƒêƒÉng k√Ω object m·ªõi\"\"\"\n",
    "        self.objects[self.next_id] = (centroid, class_id, bbox)\n",
    "        self.disappeared[self.next_id] = 0\n",
    "        self.next_id += 1\n",
    "        \n",
    "    def deregister(self, object_id):\n",
    "        \"\"\"X√≥a object ƒë√£ m·∫•t\"\"\"\n",
    "        del self.objects[object_id]\n",
    "        del self.disappeared[object_id]\n",
    "        if object_id in self.velocities:\n",
    "            del self.velocities[object_id]\n",
    "    \n",
    "    def update(self, detections):\n",
    "        \"\"\"C·∫≠p nh·∫≠t tracker theo danh s√°ch detection m·ªõi\"\"\"\n",
    "        if len(detections) == 0:\n",
    "            for object_id in list(self.disappeared.keys()):\n",
    "                self.disappeared[object_id] += 1\n",
    "                if self.disappeared[object_id] > self.max_disappeared:\n",
    "                    self.deregister(object_id)\n",
    "            return self.objects\n",
    "        \n",
    "        if len(self.objects) == 0:\n",
    "            for detection in detections:\n",
    "                self.register(*detection)\n",
    "        else:\n",
    "            object_ids = list(self.objects.keys())\n",
    "            object_centroids = [self.objects[oid][0] for oid in object_ids]\n",
    "            \n",
    "            D = np.zeros((len(object_centroids), len(detections)))\n",
    "            for i, obj_centroid in enumerate(object_centroids):\n",
    "                for j, (det_centroid, _, _) in enumerate(detections):\n",
    "                    D[i, j] = np.linalg.norm(np.array(obj_centroid) - np.array(det_centroid))\n",
    "            \n",
    "            rows = D.min(axis=1).argsort()\n",
    "            cols = D.argmin(axis=1)[rows]\n",
    "            \n",
    "            used_rows, used_cols = set(), set()\n",
    "            for row, col in zip(rows, cols):\n",
    "                if row in used_rows or col in used_cols:\n",
    "                    continue\n",
    "                if D[row, col] > self.max_distance:\n",
    "                    continue\n",
    "                object_id = object_ids[row]\n",
    "                self.objects[object_id] = detections[col]\n",
    "                self.disappeared[object_id] = 0\n",
    "                used_rows.add(row)\n",
    "                used_cols.add(col)\n",
    "            \n",
    "            unused_rows = set(range(D.shape[0])) - used_rows\n",
    "            for row in unused_rows:\n",
    "                object_id = object_ids[row]\n",
    "                self.disappeared[object_id] += 1\n",
    "                if self.disappeared[object_id] > self.max_disappeared:\n",
    "                    self.deregister(object_id)\n",
    "            \n",
    "            unused_cols = set(range(D.shape[1])) - used_cols\n",
    "            for col in unused_cols:\n",
    "                self.register(*detections[col])\n",
    "        \n",
    "        return self.objects\n",
    "\n",
    "def detect_video(model, video_path=0, conf_thres=0.4):\n",
    "    \"\"\"Nh·∫≠n d·∫°ng ph∆∞∆°ng ti·ªán giao th√¥ng v·ªõi tracking v√† t√≠nh v·∫≠n t·ªëc ·ªïn ƒë·ªãnh\"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "    if device == \"cuda\":\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        print(f\"‚úì S·ª≠ d·ª•ng GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    else:\n",
    "        print(\"‚úì S·ª≠ d·ª•ng CPU\")\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"‚ùå Kh√¥ng th·ªÉ m·ªü video: {video_path}\")\n",
    "        return\n",
    "    \n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 30\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    if frame_width > TARGET_WIDTH:\n",
    "        scale = TARGET_WIDTH / frame_width\n",
    "        frame_width = TARGET_WIDTH\n",
    "        frame_height = int(frame_height * scale)\n",
    "    else:\n",
    "        scale = 1.0\n",
    "    \n",
    "    print(f\"‚úì Video: {frame_width}x{frame_height} @ {fps:.1f} FPS\")\n",
    "    \n",
    "    tracker = VehicleTracker(\n",
    "        max_disappeared=int(fps if TRACKER_MAX_DISAPPEARED == 30 else TRACKER_MAX_DISAPPEARED),\n",
    "        max_distance=TRACKER_MAX_DISTANCE\n",
    "    )\n",
    "    prev_positions = {}\n",
    "    fps_deque = deque(maxlen=FPS_SMOOTHING_WINDOW)\n",
    "    prev_time = time.time()\n",
    "    \n",
    "    print(\"üé¨ ƒêang ch·∫°y... nh·∫•n 'q' ƒë·ªÉ tho√°t\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if scale != 1.0:\n",
    "            frame = cv2.resize(frame, (frame_width, frame_height))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            results = model(frame, conf=conf_thres, verbose=False, half=(device == \"cuda\"))\n",
    "        \n",
    "        r = results[0]\n",
    "        names = model.names\n",
    "        boxes = r.boxes\n",
    "        detections = []\n",
    "        for box in boxes:\n",
    "            cls_id = int(box.cls[0])\n",
    "            label = names[cls_id].lower()\n",
    "            conf = float(box.conf[0])\n",
    "            if label not in VEHICLES or conf < conf_thres:\n",
    "                continue\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "            bbox = (x1, y1, x2, y2)\n",
    "            detections.append(((cx, cy), cls_id, bbox))\n",
    "        \n",
    "        tracked_objects = tracker.update(detections)\n",
    "        \n",
    "        for object_id, (centroid, cls_id, bbox) in tracked_objects.items():\n",
    "            cx, cy = centroid\n",
    "            x1, y1, x2, y2 = bbox\n",
    "            label = names[cls_id].lower()\n",
    "            velocity_kmh = 0.0\n",
    "            if object_id in prev_positions:\n",
    "                px_prev, py_prev = prev_positions[object_id]\n",
    "                dist_pixels = math.sqrt((cx - px_prev)**2 + (cy - py_prev)**2)\n",
    "                velocity_px_per_sec = dist_pixels * fps\n",
    "                velocity_kmh = velocity_px_per_sec * PIXEL_TO_KMH\n",
    "                tracker.velocities[object_id].append(velocity_kmh)\n",
    "                velocity_kmh = np.mean(list(tracker.velocities[object_id]))\n",
    "            prev_positions[object_id] = (cx, cy)\n",
    "            \n",
    "            color = (0, 255, 0) if velocity_kmh < 40 else (0, 165, 255) if velocity_kmh < 80 else (0, 0, 255)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            text = f\"ID:{object_id} {label}\"\n",
    "            speed_text = f\"{velocity_kmh:.1f} km/h\"\n",
    "            (tw, th), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "            cv2.rectangle(frame, (x1, y1-th-25), (x1+tw, y1), color, -1)\n",
    "            cv2.putText(frame, text, (x1, y1-15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "            cv2.putText(frame, speed_text, (x1, y1-2), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "            cv2.circle(frame, (cx, cy), 4, color, -1)\n",
    "        \n",
    "        curr_time = time.time()\n",
    "        fps_value = 1 / (curr_time - prev_time + 1e-6)\n",
    "        fps_deque.append(fps_value)\n",
    "        avg_fps = np.mean(fps_deque)\n",
    "        prev_time = curr_time\n",
    "        \n",
    "        info_bg = np.zeros((80, 300, 3), dtype=np.uint8)\n",
    "        cv2.putText(info_bg, f\"FPS: {avg_fps:.1f}\", (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        cv2.putText(info_bg, f\"Tracked: {len(tracked_objects)}\", (10, 55), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 1)\n",
    "        frame[10:90, 10:310] = cv2.addWeighted(frame[10:90, 10:310], 0.3, info_bg, 0.7, 0)\n",
    "        \n",
    "        cv2.imshow(\"Vehicle Detection & Tracking (YOLOv11)\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"‚úì Ho√†n th√†nh!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = YOLO(MODEL_PATH)\n",
    "    detect_video(model, VIDEO_PATH, conf_thres=CONF_THRESHOLD)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
